{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58d99f8",
   "metadata": {},
   "source": [
    "# Entrega final_Lascombes Migliardi\n",
    "\n",
    "**Feature selection, modelado y evaluación**\n",
    "\n",
    "Este notebook acompaña la segunda parte del proyecto: selección de features, entrenamiento de un modelo de clasificación (Movie vs TV Show), validación y conclusiones. Ajustá rutas si corres en Colab o en otro entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d401f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports básicos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "print('imports OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e62883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Cargar dataset (ajustá la ruta si corresponde)\n",
    "df = pd.read_excel('/mnt/data/Dataset Netflix.xlsx')\n",
    "print('shape:', df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5de79",
   "metadata": {},
   "source": [
    "## 3) Preprocesamiento y feature engineering\n",
    "Separamos duración en minutos/temporadas, creamos variables derivadas (num_genres, desc_len, cast_count) y preparamos la variable target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f14466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = df.copy()\n",
    "\n",
    "# convertir año\n",
    "data['Año de publicación'] = pd.to_numeric(data['Año de publicación'], errors='coerce')\n",
    "\n",
    "# extraer duración en minutos y seasons\n",
    "def extract_duration(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    x = str(x).strip()\n",
    "    if 'min' in x:\n",
    "        try: return int(x.replace(' min',''))\n",
    "        except: return np.nan\n",
    "    return np.nan\n",
    "\n",
    "def extract_seasons(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    x = str(x).strip()\n",
    "    if 'Season' in x:\n",
    "        try: return int(x.split()[0])\n",
    "        except: return np.nan\n",
    "    return np.nan\n",
    "\n",
    "data['Duración_num'] = data['Duración'].apply(extract_duration)\n",
    "data['Seasons_num'] = data['Duración'].apply(extract_seasons)\n",
    "\n",
    "# otras features\n",
    "data['num_genres'] = data['Género'].fillna('').apply(lambda s: len([g for g in s.split(',') if g.strip()!='']))\n",
    "data['desc_len'] = data['Descripción '].fillna('').apply(len)\n",
    "data['cast_count'] = data['Reparto'].fillna('').apply(lambda s: len([p for p in s.split(',') if p.strip()!='']))\n",
    "data['director_missing'] = data['Director'].isna().astype(int)\n",
    "\n",
    "# simplificar paises\n",
    "data['Pais'] = data['Pais'].fillna('Unknown')\n",
    "top_countries = data['Pais'].value_counts().head(10).index.tolist()\n",
    "data['Pais_top'] = data['Pais'].apply(lambda x: x if x in top_countries else 'Other')\n",
    "\n",
    "# target\n",
    "data = data[~data['Tipo'].isna()]\n",
    "le = LabelEncoder()\n",
    "data['target'] = le.fit_transform(data['Tipo'])  # Movie/TV Show -> numeric\n",
    "print('target classes:', le.classes_)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dac06",
   "metadata": {},
   "source": [
    "### 3.1 Valores faltantes (revisión rápida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# valores faltantes por columna\n",
    "data.isnull().sum().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0d088",
   "metadata": {},
   "source": [
    "## 4) Preparar matriz de features y preprocesador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_feats = ['Año de publicación','Duración_num','Seasons_num','num_genres','desc_len','cast_count','director_missing']\n",
    "cat_feats = ['Pais_top']\n",
    "\n",
    "num_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_feats), ('cat', cat_transformer, cat_feats)], remainder='drop')\n",
    "\n",
    "X = preprocessor.fit_transform(data)\n",
    "# obtener nombres de columnas resultantes\n",
    "ohe_cols = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_feats)\n",
    "feature_names = num_feats + list(ohe_cols)\n",
    "print('features total:', len(feature_names))\n",
    "feature_names[:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b7075",
   "metadata": {},
   "source": [
    "## 5) Selección de features (SelectKBest - mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = data['target'].values\n",
    "k = min(10, X.shape[1])\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "selector.fit(X, y)\n",
    "mask = selector.get_support()\n",
    "selected_features = [feature_names[i] for i, m in enumerate(mask) if m]\n",
    "scores = selector.scores_[mask]\n",
    "print('SelectKBest selected:')\n",
    "for f, s in zip(selected_features, scores):\n",
    "    print(f'{f}: {s:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf5b50",
   "metadata": {},
   "source": [
    "## 6) Selección de features (RFE con RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0319ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "n_select = min(8, X.shape[1])\n",
    "rfe = RFE(estimator=rf, n_features_to_select=n_select, step=1)\n",
    "rfe.fit(X, y)\n",
    "rfe_mask = rfe.get_support()\n",
    "rfe_features = [feature_names[i] for i, m in enumerate(rfe_mask) if m]\n",
    "print('RFE selected:')\n",
    "for f in rfe_features:\n",
    "    print('-', f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f482d5",
   "metadata": {},
   "source": [
    "## 7) Entrenamiento y evaluación del modelo (RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c94d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_mask = rfe_mask if len(rfe_features)>0 else np.ones(len(feature_names), dtype=bool)\n",
    "X_sel = X[:, use_mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, stratify=y, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "print(f'Precision: {prec:.3f}')\n",
    "print(f'Recall: {rec:.3f}')\n",
    "print(f'F1: {f1:.3f}')\n",
    "print(f'ROC AUC: {roc:.3f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicho'); plt.ylabel('Real'); plt.title('Matriz de confusión')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f606d1",
   "metadata": {},
   "source": [
    "## 8) Importancia de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = clf.feature_importances_\n",
    "selected_names = [n for i,n in enumerate(feature_names) if use_mask[i]]\n",
    "feat_imp = pd.DataFrame({'feature': selected_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=feat_imp.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 features (RandomForest)')\n",
    "plt.show()\n",
    "feat_imp.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb933fc1",
   "metadata": {},
   "source": [
    "## 9) Validación cruzada (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X_sel, y, cv=cv, scoring='f1')\n",
    "print('CV F1 scores:', cv_scores)\n",
    "print('Mean CV F1:', cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f7e13",
   "metadata": {},
   "source": [
    "## 10) Valores faltantes y tratamiento\n",
    "Muestra los conteos de valores faltantes y describe la estrategia de imputación (mediana para numéricas, constante para categóricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78648568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# valores faltantes (original)\n",
    "df.isnull().sum().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd182702",
   "metadata": {},
   "source": [
    
